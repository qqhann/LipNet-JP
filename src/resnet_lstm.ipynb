{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype_float = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['A', 'I', 'U', 'E', 'O', 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = Path('/home/jphacks/LipNet-JP/')\n",
    "youtube_id = '1'\n",
    "# youtube_id = '2'\n",
    "spk = 's{}'.format(youtube_id)\n",
    "txtpath = workdir / 'data/align' / 'output{}word.align'.format(youtube_id)\n",
    "aligned_lm_path = Path('/home/jphacks/LipNet-JP/data/processed2/{0}/{0}_aligned.csv'.format(youtube_id))\n",
    "lm_path = Path('/home/jphacks/LipNet-JP/data/processed/{0}/{0}.csv'.format(youtube_id))\n",
    "croppeddir = Path('/home/jphacks/LipNet-JP/data/processed2/{0}/{0}_aligned_aligned_cropped'.format(youtube_id))\n",
    "assert croppeddir.exists()\n",
    "\n",
    "datadir = Path('/home/jphacks/LipNet-JP/data')\n",
    "videodir = datadir / 'lip_video'\n",
    "txtdir = datadir / 'align_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(152),\n",
    "#     transforms.CenterCrop(152),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(152),\n",
    "    transforms.CenterCrop(152),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.CenterCrop((122, 122)),\n",
    "#     transforms.CenterCrop((112, 112)),\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.4161,],[0.1688,]),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img = Image.open(str(list(croppeddir.iterdir())[0]))\n",
    "input_tensor = preprocess(img)\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inwidth, inheight = 160, 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nana\n",
      "nee\n",
      "oo\n",
      "aao\n",
      "oouu\n",
      "eeu\n",
      "ne\n",
      "an\n",
      "aai\n",
      "iai\n",
      "ani\n",
      "anae\n",
      "onai\n",
      "aao\n",
      "oo\n",
      "nee\n",
      "nuiuuu\n",
      "ooa\n",
      "ai\n",
      "ooon\n",
      "au\n",
      "oe\n",
      "no\n",
      "ii\n",
      "iu\n",
      "a\n",
      "ina\n",
      "nai\n",
      "ae\n",
      "a\n",
      "e\n",
      "nani\n",
      "ae\n",
      "ina\n",
      "enoo\n",
      "iou\n",
      "uu\n",
      "nani\n",
      "ae\n",
      "ni\n",
      "oo\n",
      "aiei\n",
      "io\n",
      "aa\n",
      "ae\n",
      "a\n",
      "o\n",
      "oo\n",
      "a\n",
      "io\n",
      "oo\n",
      "a\n",
      "ii\n",
      "i\n",
      "oe\n",
      "no\n",
      "anae\n",
      "aaii\n",
      "o\n",
      "uunauoo\n",
      "onenu\n",
      "aiin\n",
      "i\n",
      "iun\n",
      "no\n",
      "oiii\n",
      "o\n",
      "i\n",
      "a\n",
      "oee\n",
      "uuau\n",
      "o\n",
      "ne\n",
      "e\n",
      "io\n",
      "a\n",
      "oo\n",
      "aao\n",
      "oaa\n",
      "i\n",
      "aiau\n",
      "iu\n",
      "eo\n",
      "nani\n",
      "iun\n",
      "ooi\n",
      "au\n",
      "oo\n",
      "oa\n",
      "iooenei\n",
      "anae\n",
      "anaa\n",
      "nau\n",
      "iun\n",
      "ui\n",
      "ni\n",
      "ii\n",
      "ie\n",
      "e\n",
      "oe\n",
      "anaeaa\n",
      "a\n",
      "oion\n",
      "eu\n",
      "ono\n",
      "nai\n",
      "aa\n",
      "uuau\n",
      "aa\n",
      "ooo\n",
      "oie\n",
      "ue\n",
      "aoea\n",
      "oeu\n",
      "ioo\n",
      "uia\n",
      "iu\n",
      "aeo\n",
      "ion\n",
      "ni\n",
      "nee\n",
      "o\n",
      "oiu\n",
      "e\n",
      "a\n",
      "anoo\n",
      "oa\n",
      "ooao\n",
      "oa\n",
      "iu\n",
      "iii\n",
      "i\n",
      "euo\n",
      "eo\n",
      "ae\n",
      "oau\n",
      "e\n",
      "iu\n",
      "ae\n",
      "a\n",
      "euni\n",
      "oo\n",
      "ia\n",
      "a\n",
      "ue\n",
      "aiaa\n",
      "i\n",
      "oa\n",
      "au\n",
      "e\n",
      "aa\n",
      "ia\n",
      "na\n",
      "aa\n",
      "ea\n",
      "anoii\n",
      "e\n",
      "iu\n",
      "a\n",
      "ia\n",
      "ai\n",
      "oe\n",
      "o\n",
      "uuau\n",
      "uen\n",
      "e\n",
      "io\n",
      "a\n",
      "uou\n",
      "anoii\n",
      "o\n",
      "ooini\n",
      "eoo\n",
      "uae\n",
      "iu\n",
      "ooini\n",
      "eoo\n",
      "nan\n",
      "eeoo\n",
      "nana\n",
      "nee\n",
      "aao\n",
      "o\n",
      "oouu\n",
      "eeu\n",
      "ei\n",
      "ne\n",
      "an\n",
      "ie\n",
      "aai\n",
      "iai\n",
      "ani\n",
      "anae\n",
      "oe\n",
      "onai\n",
      "aao\n",
      "ono\n",
      "eeu\n",
      "iun\n",
      "no\n",
      "ooi\n",
      "au\n",
      "oo\n",
      "anan\n",
      "ono\n",
      "ian\n",
      "uoeu\n",
      "oou\n",
      "aoea\n",
      "oe\n",
      "aiin\n",
      "nana\n",
      "eain\n",
      "no\n",
      "enoo\n",
      "oa\n",
      "eain\n",
      "enoo\n",
      "e\n",
      "oo\n",
      "no\n",
      "ae\n",
      "eo\n",
      "nai\n",
      "aeo\n",
      "nana\n",
      "eoo\n",
      "aai\n",
      "oa\n",
      "ooi\n",
      "a\n",
      "eain\n",
      "iai\n",
      "ooi\n",
      "o\n",
      "uoi\n",
      "ooi\n",
      "a\n",
      "enen\n",
      "oouu\n",
      "oa\n",
      "oouu\n",
      "no\n",
      "enen\n",
      "nani\n",
      "nana\n",
      "eain\n",
      "ui\n",
      "oo\n",
      "enoo\n",
      "i\n",
      "ona\n",
      "an\n",
      "eoo\n",
      "oouu\n",
      "eain\n",
      "ae\n",
      "o\n",
      "eoo\n",
      "ne\n",
      "no\n",
      "on\n",
      "oo\n",
      "oouu\n",
      "ai\n",
      "eain\n",
      "oooi\n",
      "oo\n",
      "ni\n",
      "iai\n",
      "oa\n",
      "on\n",
      "i\n",
      "ooioi\n",
      "oe\n",
      "a\n",
      "nana\n",
      "uuu\n",
      "ni\n",
      "aa\n",
      "ni\n",
      "oouu\n",
      "io\n",
      "oe\n",
      "ono\n",
      "eain\n",
      "i\n",
      "a\n",
      "oa\n",
      "oouu\n",
      "enau\n",
      "no\n",
      "iai\n",
      "e\n",
      "i\n",
      "oi\n",
      "i\n",
      "a\n",
      "nani\n",
      "anae\n",
      "i\n",
      "uu\n",
      "io\n",
      "ni\n",
      "ui\n",
      "aa\n",
      "n\n",
      "aia\n",
      "aaaa\n",
      "on\n",
      "ooioi\n",
      "iu\n",
      "uuoo\n",
      "a\n",
      "e\n",
      "aa\n",
      "oeu\n",
      "nana\n",
      "oouu\n",
      "iai\n",
      "oo\n",
      "oouu\n",
      "e\n",
      "euni\n",
      "aa\n",
      "aiau\n",
      "no\n",
      "nana\n",
      "en\n",
      "iai\n",
      "aan\n",
      "au\n",
      "eo\n",
      "ona\n",
      "oo\n",
      "ia\n",
      "nau\n",
      "ae\n",
      "ii\n",
      "ue\n",
      "on\n",
      "ne\n",
      "on\n",
      "uu\n",
      "oo\n",
      "enen\n",
      "eiu\n",
      "ae\n",
      "o\n",
      "aaa\n",
      "nana\n",
      "oouu\n",
      "uu\n",
      "oueu\n",
      "i\n",
      "ni\n",
      "iu\n",
      "an\n",
      "ie\n",
      "aa\n",
      "oa\n",
      "oo\n",
      "i\n",
      "ae\n",
      "nai\n",
      "aa\n",
      "oa\n",
      "oouu\n",
      "a\n",
      "aani\n",
      "iun\n",
      "a\n",
      "ae\n",
      "aa\n",
      "nai\n",
      "oi\n",
      "naa\n",
      "oou\n",
      "aa\n",
      "oooo\n",
      "e\n",
      "uiu\n",
      "ono\n",
      "oooo\n",
      "naa\n",
      "ni\n",
      "ai\n",
      "aii\n",
      "ni\n",
      "aau\n",
      "iai\n",
      "iu\n",
      "uoi\n",
      "aaa\n",
      "nee\n",
      "uuii\n",
      "ai\n",
      "o\n",
      "e\n",
      "uen\n",
      "no\n",
      "enoo\n",
      "oo\n",
      "ia\n",
      "ani\n",
      "uuu\n",
      "ni\n",
      "anau\n",
      "auuu\n",
      "uu\n",
      "iu\n",
      "ian\n",
      "eeu\n",
      "nane\n",
      "aao\n",
      "oaa\n",
      "e\n",
      "oouu\n",
      "oi\n",
      "no\n",
      "ni\n",
      "ian\n",
      "iai\n",
      "oo\n",
      "uae\n",
      "a\n",
      "ooioi\n",
      "a\n",
      "oou\n",
      "eu\n",
      "o\n",
      "oouu\n",
      "ne\n",
      "anaeaa\n",
      "o\n",
      "au\n",
      "aa\n",
      "ioio\n",
      "aa\n",
      "eioo\n",
      "i\n",
      "iu\n",
      "e\n",
      "no\n",
      "aa\n",
      "anoii\n",
      "o\n",
      "iun\n",
      "e\n",
      "iui\n",
      "iun\n",
      "e\n",
      "oo\n",
      "aien\n",
      "i\n",
      "iu\n",
      "ooo\n",
      "ni\n",
      "eoo\n",
      "uai\n",
      "oe\n",
      "nana\n",
      "ae\n",
      "oie\n",
      "oa\n",
      "ae\n",
      "o\n",
      "eai\n",
      "oa\n",
      "enen\n",
      "nau\n",
      "oe\n",
      "a\n",
      "oe\n",
      "a\n",
      "oiinau\n",
      "ooo\n",
      "ae\n",
      "oe\n",
      "oo\n",
      "oe\n",
      "ni\n",
      "on\n",
      "iaueu\n",
      "oe\n",
      "oo\n",
      "ae\n",
      "o\n",
      "i\n",
      "iio\n",
      "oo\n",
      "anau\n",
      "aaa\n",
      "a\n",
      "ue\n",
      "aien\n",
      "ai\n",
      "oe\n",
      "a\n",
      "iau\n",
      "aaa\n",
      "i\n",
      "ue\n",
      "io\n",
      "oa\n",
      "oou\n",
      "ono\n",
      "au\n",
      "a\n",
      "oo\n",
      "ai\n",
      "uio\n",
      "inaan\n",
      "i\n",
      "an\n",
      "ai\n",
      "nauoo\n",
      "ne\n",
      "oo\n",
      "ina\n",
      "o\n",
      "nee\n",
      "ae\n",
      "aui\n",
      "eaa\n",
      "ioo\n",
      "io\n",
      "aie\n",
      "aa\n",
      "ouiu\n",
      "oinaa\n",
      "oa\n",
      "oou\n",
      "o\n",
      "iun\n",
      "no\n",
      "ooii\n",
      "oa\n",
      "i\n",
      "eu\n"
     ]
    }
   ],
   "source": [
    "aligned_lm_df = pd.read_csv(str(aligned_lm_path))\n",
    "aligned_lm_df['timestamp'] = (aligned_lm_df['frame'] - 1) * (1/30)\n",
    "\n",
    "with open(txtpath, 'r') as f:\n",
    "    txt = json.load(f)\n",
    "\n",
    "aligned_lm_df['target'] = -1\n",
    "\n",
    "for word in txt:\n",
    "    print(\"\".join([c[\"word\"] for c in word]))\n",
    "    \n",
    "    for c in word:\n",
    "        aligned_lm_df.loc[(aligned_lm_df.timestamp >= c['start']) & (aligned_lm_df.timestamp < c['end']), 'target'] = letters.index(c['word'].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>face_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077917</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>-0.952641</td>\n",
       "      <td>-0.316540</td>\n",
       "      <td>0.281786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077251</td>\n",
       "      <td>0.272675</td>\n",
       "      <td>-0.959000</td>\n",
       "      <td>-0.317211</td>\n",
       "      <td>0.262823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078179</td>\n",
       "      <td>0.285228</td>\n",
       "      <td>-0.955266</td>\n",
       "      <td>-0.303922</td>\n",
       "      <td>0.250068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082503</td>\n",
       "      <td>0.286471</td>\n",
       "      <td>-0.954530</td>\n",
       "      <td>-0.309884</td>\n",
       "      <td>0.242810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072832</td>\n",
       "      <td>0.289409</td>\n",
       "      <td>-0.954431</td>\n",
       "      <td>-0.322312</td>\n",
       "      <td>0.255926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8833</td>\n",
       "      <td>8834</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211204</td>\n",
       "      <td>0.278979</td>\n",
       "      <td>-0.936784</td>\n",
       "      <td>-0.193433</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.433333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8834</td>\n",
       "      <td>8835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156352</td>\n",
       "      <td>0.355814</td>\n",
       "      <td>-0.921385</td>\n",
       "      <td>-0.199006</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.466667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8835</td>\n",
       "      <td>8836</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206907</td>\n",
       "      <td>0.507335</td>\n",
       "      <td>-0.836541</td>\n",
       "      <td>-0.249781</td>\n",
       "      <td>0.325380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.500000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8836</td>\n",
       "      <td>8837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195739</td>\n",
       "      <td>0.543425</td>\n",
       "      <td>-0.816318</td>\n",
       "      <td>-0.214373</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.533333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8837</td>\n",
       "      <td>8838</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214522</td>\n",
       "      <td>0.550760</td>\n",
       "      <td>-0.806625</td>\n",
       "      <td>-0.234075</td>\n",
       "      <td>0.419669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.566667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8838 rows × 716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frame   face_id   timestamp   confidence   success   gaze_0_x  \\\n",
       "0         1         0         0.0         0.98         1   0.077917   \n",
       "1         2         0         0.0         0.98         1   0.077251   \n",
       "2         3         0         0.0         0.98         1   0.078179   \n",
       "3         4         0         0.0         0.98         1   0.082503   \n",
       "4         5         0         0.0         0.98         1   0.072832   \n",
       "...     ...       ...         ...          ...       ...        ...   \n",
       "8833   8834         0         0.0         0.93         1   0.211204   \n",
       "8834   8835         0         0.0         0.88         1   0.156352   \n",
       "8835   8836         0         0.0         0.88         1   0.206907   \n",
       "8836   8837         0         0.0         0.88         1   0.195739   \n",
       "8837   8838         0         0.0         0.93         1   0.214522   \n",
       "\n",
       "       gaze_0_y   gaze_0_z   gaze_1_x   gaze_1_y  ...   AU15_c   AU17_c  \\\n",
       "0      0.293945  -0.952641  -0.316540   0.281786  ...      0.0      0.0   \n",
       "1      0.272675  -0.959000  -0.317211   0.262823  ...      0.0      0.0   \n",
       "2      0.285228  -0.955266  -0.303922   0.250068  ...      0.0      0.0   \n",
       "3      0.286471  -0.954530  -0.309884   0.242810  ...      0.0      0.0   \n",
       "4      0.289409  -0.954431  -0.322312   0.255926  ...      0.0      0.0   \n",
       "...         ...        ...        ...        ...  ...      ...      ...   \n",
       "8833   0.278979  -0.936784  -0.193433   0.300300  ...      0.0      1.0   \n",
       "8834   0.355814  -0.921385  -0.199006   0.464844  ...      0.0      1.0   \n",
       "8835   0.507335  -0.836541  -0.249781   0.325380  ...      0.0      1.0   \n",
       "8836   0.543425  -0.816318  -0.214373   0.394439  ...      0.0      1.0   \n",
       "8837   0.550760  -0.806625  -0.234075   0.419669  ...      0.0      1.0   \n",
       "\n",
       "       AU20_c   AU23_c   AU25_c   AU26_c   AU28_c   AU45_c   timestamp  target  \n",
       "0         0.0      0.0      1.0      1.0      0.0      0.0    0.000000      -1  \n",
       "1         0.0      0.0      1.0      1.0      0.0      0.0    0.033333      -1  \n",
       "2         0.0      0.0      1.0      0.0      0.0      0.0    0.066667      -1  \n",
       "3         0.0      0.0      1.0      1.0      0.0      0.0    0.100000      -1  \n",
       "4         0.0      0.0      1.0      1.0      0.0      0.0    0.133333      -1  \n",
       "...       ...      ...      ...      ...      ...      ...         ...     ...  \n",
       "8833      0.0      0.0      0.0      0.0      0.0      0.0  294.433333      -1  \n",
       "8834      0.0      0.0      0.0      0.0      0.0      0.0  294.466667      -1  \n",
       "8835      0.0      0.0      0.0      0.0      0.0      0.0  294.500000      -1  \n",
       "8836      0.0      0.0      0.0      0.0      0.0      0.0  294.533333      -1  \n",
       "8837      0.0      0.0      0.0      0.0      0.0      0.0  294.566667      -1  \n",
       "\n",
       "[8838 rows x 716 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_lm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = []\n",
    "targetlist = []\n",
    "_lett_counter = {l: 0 for l in letters}\n",
    "for idx, row in aligned_lm_df.iterrows():\n",
    "    if row.target < 0:\n",
    "        continue\n",
    "    imgpath = croppeddir / 'frame_det_00_{:06d}.bmp'.format(int(row.frame))\n",
    "    img = Image.open(str(imgpath))\n",
    "    input_tensor = preprocess(img)\n",
    "    size = np.asarray(img).shape\n",
    "    if size != (inheight, inwidth, 3):\n",
    "        continue\n",
    "    # img = np.moveaxis(img, 2, 0)  # (80, 160, 3) -> (3, 80, 160)\n",
    "    imglist.append(input_tensor)\n",
    "    targetlist.append(int(row.target))\n",
    "    _lett_counter[letters[int(row.target)]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipDataset(Dataset):\n",
    "    def __init__(self, imglist, targetlist, idxlist):\n",
    "        self.imglist = imglist\n",
    "        self.targetlist = targetlist\n",
    "        self.idxlist = idxlist\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idxlist)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.imglist[self.idxlist[idx]], self.targetlist[self.idxlist[idx]])\n",
    "    \n",
    "    def _to_list(self):\n",
    "        return [self[i] for i in range(len(self))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3196 799 999\n"
     ]
    }
   ],
   "source": [
    "train_idxlist, test_idxlist = train_test_split(list(range(len(imglist))), test_size=.2, shuffle=True)\n",
    "train_idxlist, validate_idxlist = train_test_split(train_idxlist, test_size=.2, shuffle=True)\n",
    "\n",
    "print(len(train_idxlist), len(validate_idxlist), len(test_idxlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lipdataset = LipDataset(imglist, targetlist, train_idxlist)\n",
    "validate_lipdataset = LipDataset(imglist, targetlist, validate_idxlist)\n",
    "test_lipdataset = LipDataset(imglist, targetlist, test_idxlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_lipdataset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "validateloader = torch.utils.data.DataLoader(validate_lipdataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_lipdataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torchvision.models.resnet34(pretrained=True, num_classes=6).to(device)\n",
    "net = torchvision.models.resnet34(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.5, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(iterator):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        acc = (predicted == target.to(device)).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() / dtype_float(BATCH_SIZE)\n",
    "        epoch_acc += acc.item() / dtype_float(BATCH_SIZE)\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (data, target) in enumerate(iterator):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "                        \n",
    "            output = model(data.type(dtype_float))\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            acc = (predicted == target.to(device)).sum()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.109 | Train Acc: 27.81%\n",
      "\t Val. Loss: 0.097 |  Val. Acc: 1.39%\n",
      "Epoch: 02 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.093 | Train Acc: 33.08%\n",
      "\t Val. Loss: 0.105 |  Val. Acc: 1.34%\n",
      "Epoch: 03 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.090 | Train Acc: 36.86%\n",
      "\t Val. Loss: 0.100 |  Val. Acc: 1.49%\n",
      "Epoch: 04 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.085 | Train Acc: 39.33%\n",
      "\t Val. Loss: 0.105 |  Val. Acc: 1.40%\n",
      "Epoch: 05 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.079 | Train Acc: 44.38%\n",
      "\t Val. Loss: 0.097 |  Val. Acc: 1.62%\n",
      "Epoch: 06 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.072 | Train Acc: 50.37%\n",
      "\t Val. Loss: 0.102 |  Val. Acc: 1.86%\n",
      "Epoch: 07 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.061 | Train Acc: 59.39%\n",
      "\t Val. Loss: 0.105 |  Val. Acc: 2.11%\n",
      "Epoch: 08 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.053 | Train Acc: 64.95%\n",
      "\t Val. Loss: 0.104 |  Val. Acc: 2.12%\n",
      "Epoch: 09 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.043 | Train Acc: 71.82%\n",
      "\t Val. Loss: 0.112 |  Val. Acc: 2.30%\n",
      "Epoch: 10 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.036 | Train Acc: 75.50%\n",
      "\t Val. Loss: 0.115 |  Val. Acc: 2.25%\n",
      "Epoch: 11 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.032 | Train Acc: 79.21%\n",
      "\t Val. Loss: 0.101 |  Val. Acc: 2.78%\n",
      "Epoch: 12 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.026 | Train Acc: 83.68%\n",
      "\t Val. Loss: 0.105 |  Val. Acc: 2.64%\n",
      "Epoch: 13 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.018 | Train Acc: 88.05%\n",
      "\t Val. Loss: 0.146 |  Val. Acc: 2.37%\n",
      "Epoch: 14 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.015 | Train Acc: 90.57%\n",
      "\t Val. Loss: 0.110 |  Val. Acc: 2.94%\n",
      "Epoch: 15 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.014 | Train Acc: 91.95%\n",
      "\t Val. Loss: 0.119 |  Val. Acc: 2.89%\n",
      "Epoch: 16 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.012 | Train Acc: 92.95%\n",
      "\t Val. Loss: 0.110 |  Val. Acc: 3.05%\n",
      "Epoch: 17 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.010 | Train Acc: 93.48%\n",
      "\t Val. Loss: 0.116 |  Val. Acc: 2.82%\n",
      "Epoch: 18 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.011 | Train Acc: 93.76%\n",
      "\t Val. Loss: 0.112 |  Val. Acc: 3.00%\n",
      "Epoch: 19 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.010 | Train Acc: 93.85%\n",
      "\t Val. Loss: 0.118 |  Val. Acc: 2.91%\n",
      "Epoch: 20 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.009 | Train Acc: 94.85%\n",
      "\t Val. Loss: 0.129 |  Val. Acc: 2.91%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(net, trainloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(net, validateloader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(net.state_dict(), 'tut5-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, iterator, optimizer, criterion):\n",
    "    model.eval()\n",
    "    class_correct = [0.] * len(letters)\n",
    "    class_total = [0.] * len(letters)\n",
    "    with torch.no_grad():\n",
    "        for data in iterator:\n",
    "            images, labels = data\n",
    "            outputs = net(images.type(dtype_float))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels.to(device)).squeeze()\n",
    "            class_correct[labels.item()] += c.item() * 1\n",
    "            class_total[labels.item()] += 1\n",
    "\n",
    "    for i, l in enumerate(letters):\n",
    "        print('Accuracy of    {}: {:.4f} ({:4d}/{:4d})'.format(l, class_correct[i]/class_total[i] if class_total[i] > 0 else 0, int(class_correct[i]), int(class_total[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, testloader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
